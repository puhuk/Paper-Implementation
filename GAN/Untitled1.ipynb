{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f2526e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b88b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa40b445a39c44a1aa47bc0280172ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af52402097eb4388a5af172d20608f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 503: Service Unavailable\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23058be9c56348a287f10285af8e699d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0acb86bd2542dd97d893de26ac71f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a1101477/2021-1/MLDL/mldl/lib/python3.7/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,),(0.5,))\n",
    "                ])\n",
    "to_image = transforms.ToPILImage()\n",
    "trainset = MNIST(root='./data/', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4083f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for i, [image, label] in enumerate(trainloader):\n",
    "    print(i, image.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d66d541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e654c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.n_features = 128\n",
    "        self.n_out = 784\n",
    "        self.fc0 = nn.Sequential(\n",
    "                    nn.Linear(self.n_features, 256),\n",
    "                    nn.LeakyReLU(0.2)\n",
    "                    )\n",
    "        self.fc1 = nn.Sequential(\n",
    "                    nn.Linear(256, 512),\n",
    "                    nn.LeakyReLU(0.2)\n",
    "                    )\n",
    "        self.fc2 = nn.Sequential(\n",
    "                    nn.Linear(512, 1024),\n",
    "                    nn.LeakyReLU(0.2)\n",
    "                    )\n",
    "        self.fc3 = nn.Sequential(\n",
    "                    nn.Linear(1024, self.n_out),\n",
    "                    nn.Tanh()\n",
    "                    )\n",
    "    def forward(self, x):\n",
    "        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.n_in = 784\n",
    "        self.n_out = 1\n",
    "        self.fc0 = nn.Sequential(\n",
    "                    nn.Linear(self.n_in, 1024),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Dropout(0.3)\n",
    "                    )\n",
    "        self.fc1 = nn.Sequential(\n",
    "                    nn.Linear(1024, 512),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Dropout(0.3)\n",
    "                    )\n",
    "        self.fc2 = nn.Sequential(\n",
    "                    nn.Linear(512, 256),\n",
    "                    nn.LeakyReLU(0.2),\n",
    "                    nn.Dropout(0.3)\n",
    "                    )\n",
    "        self.fc3 = nn.Sequential(\n",
    "                    nn.Linear(256, self.n_out),\n",
    "                    nn.Sigmoid()\n",
    "                    )\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.fc0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20e7186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "g_optim = optim.Adam(generator.parameters(), lr=2e-4)\n",
    "d_optim = optim.Adam(discriminator.parameters(), lr=2e-4)\n",
    "\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "images = []\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def noise(n, n_features=128):\n",
    "    return Variable(torch.randn(n, n_features)).to(device)\n",
    "\n",
    "def make_ones(size):\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    return data.to(device)\n",
    "\n",
    "def make_zeros(size):\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    return data.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b47278e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    n = real_data.size(0)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    prediction_real = discriminator(real_data)\n",
    "    error_real = criterion(prediction_real, make_ones(n))\n",
    "    error_real.backward()\n",
    "\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    error_fake = criterion(prediction_fake, make_zeros(n))\n",
    "    \n",
    "    error_fake.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return error_real + error_fake\n",
    "\n",
    "def train_generator(optimizer, fake_data):\n",
    "    n = fake_data.size(0)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    prediction = discriminator(fake_data)\n",
    "    error = criterion(prediction, make_ones(n))\n",
    "    \n",
    "    error.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6637a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: g_loss: 2.88339138 d_loss: 0.95510399\n",
      "Epoch 1: g_loss: 1.81115687 d_loss: 1.02838194\n",
      "Epoch 2: g_loss: 2.47281313 d_loss: 0.77506012\n",
      "Epoch 3: g_loss: 2.61726665 d_loss: 0.59707808\n",
      "Epoch 4: g_loss: 3.35524750 d_loss: 0.43079934\n",
      "Epoch 5: g_loss: 2.89860702 d_loss: 0.53202575\n",
      "Epoch 6: g_loss: 2.76994109 d_loss: 0.58541030\n",
      "Epoch 7: g_loss: 2.57045937 d_loss: 0.57326770\n",
      "Epoch 8: g_loss: 2.65082765 d_loss: 0.57668263\n",
      "Epoch 9: g_loss: 2.42610359 d_loss: 0.62487388\n",
      "Epoch 10: g_loss: 2.30858684 d_loss: 0.66642123\n",
      "Epoch 11: g_loss: 2.04738617 d_loss: 0.73612946\n",
      "Epoch 12: g_loss: 2.01965261 d_loss: 0.76425332\n",
      "Epoch 13: g_loss: 1.88807273 d_loss: 0.81586903\n",
      "Epoch 14: g_loss: 1.89055574 d_loss: 0.83553463\n",
      "Epoch 15: g_loss: 1.79148924 d_loss: 0.84527814\n",
      "Epoch 16: g_loss: 1.71810889 d_loss: 0.85064739\n",
      "Epoch 17: g_loss: 1.69372201 d_loss: 0.87936336\n",
      "Epoch 18: g_loss: 1.72564459 d_loss: 0.85618520\n",
      "Epoch 19: g_loss: 1.67952538 d_loss: 0.87805218\n",
      "Epoch 20: g_loss: 1.57553232 d_loss: 0.92156512\n",
      "Epoch 21: g_loss: 1.57665431 d_loss: 0.92256588\n",
      "Epoch 22: g_loss: 1.55083084 d_loss: 0.92913878\n",
      "Epoch 23: g_loss: 1.50134492 d_loss: 0.96981013\n",
      "Epoch 24: g_loss: 1.47200298 d_loss: 0.96406627\n",
      "Epoch 25: g_loss: 1.47775614 d_loss: 0.97436309\n",
      "Epoch 26: g_loss: 1.50426221 d_loss: 0.95444554\n",
      "Epoch 27: g_loss: 1.44139481 d_loss: 0.98036593\n",
      "Epoch 28: g_loss: 1.36839736 d_loss: 1.00980818\n",
      "Epoch 29: g_loss: 1.35918522 d_loss: 1.03525233\n",
      "Epoch 30: g_loss: 1.29642701 d_loss: 1.04880023\n",
      "Epoch 31: g_loss: 1.29367268 d_loss: 1.05370760\n",
      "Epoch 32: g_loss: 1.32404721 d_loss: 1.04596853\n",
      "Epoch 33: g_loss: 1.33324623 d_loss: 1.03925347\n",
      "Epoch 34: g_loss: 1.29949689 d_loss: 1.05333388\n",
      "Epoch 35: g_loss: 1.30781770 d_loss: 1.05238926\n",
      "Epoch 36: g_loss: 1.25399256 d_loss: 1.07822025\n",
      "Epoch 37: g_loss: 1.25137103 d_loss: 1.08595932\n",
      "Epoch 38: g_loss: 1.24539816 d_loss: 1.08090627\n",
      "Epoch 39: g_loss: 1.23351681 d_loss: 1.08592486\n",
      "Epoch 40: g_loss: 1.19010448 d_loss: 1.10473001\n",
      "Epoch 41: g_loss: 1.19537616 d_loss: 1.10529876\n",
      "Epoch 42: g_loss: 1.17771375 d_loss: 1.12149012\n",
      "Epoch 43: g_loss: 1.15538013 d_loss: 1.12934315\n",
      "Epoch 44: g_loss: 1.17664814 d_loss: 1.12389803\n",
      "Epoch 45: g_loss: 1.14338446 d_loss: 1.13636899\n",
      "Epoch 46: g_loss: 1.14611781 d_loss: 1.14137876\n",
      "Epoch 47: g_loss: 1.15426958 d_loss: 1.13289499\n",
      "Epoch 48: g_loss: 1.13008821 d_loss: 1.14479470\n",
      "Epoch 49: g_loss: 1.13052988 d_loss: 1.15076292\n",
      "Epoch 50: g_loss: 1.09139526 d_loss: 1.16213858\n",
      "Epoch 51: g_loss: 1.07880390 d_loss: 1.17766130\n",
      "Epoch 52: g_loss: 1.07451963 d_loss: 1.17119360\n",
      "Epoch 53: g_loss: 1.04393244 d_loss: 1.19208145\n",
      "Epoch 54: g_loss: 1.05072641 d_loss: 1.18899679\n",
      "Epoch 55: g_loss: 1.06472433 d_loss: 1.18080544\n",
      "Epoch 56: g_loss: 1.06818521 d_loss: 1.17858529\n",
      "Epoch 57: g_loss: 1.06279576 d_loss: 1.18225622\n",
      "Epoch 58: g_loss: 1.00999725 d_loss: 1.20709312\n",
      "Epoch 59: g_loss: 1.02109885 d_loss: 1.20858288\n",
      "Epoch 60: g_loss: 1.04665685 d_loss: 1.20147002\n",
      "Epoch 61: g_loss: 1.02523029 d_loss: 1.20057249\n",
      "Epoch 62: g_loss: 0.99727941 d_loss: 1.21414840\n",
      "Epoch 63: g_loss: 1.02094615 d_loss: 1.21160805\n",
      "Epoch 64: g_loss: 1.03048503 d_loss: 1.20498192\n",
      "Epoch 65: g_loss: 0.99614888 d_loss: 1.21408296\n",
      "Epoch 66: g_loss: 1.00324750 d_loss: 1.22787464\n",
      "Epoch 67: g_loss: 1.00423217 d_loss: 1.22057426\n",
      "Epoch 68: g_loss: 0.98431772 d_loss: 1.22035003\n",
      "Epoch 69: g_loss: 0.99972832 d_loss: 1.22319996\n",
      "Epoch 70: g_loss: 0.99022788 d_loss: 1.22208083\n",
      "Epoch 71: g_loss: 0.98832279 d_loss: 1.22420752\n",
      "Epoch 72: g_loss: 1.00015891 d_loss: 1.21849048\n",
      "Epoch 73: g_loss: 0.98304468 d_loss: 1.22889483\n",
      "Epoch 74: g_loss: 0.94763732 d_loss: 1.24967730\n",
      "Epoch 75: g_loss: 0.94453239 d_loss: 1.24729812\n",
      "Epoch 76: g_loss: 0.98050839 d_loss: 1.23295939\n",
      "Epoch 77: g_loss: 0.96034640 d_loss: 1.23687434\n",
      "Epoch 78: g_loss: 0.97905475 d_loss: 1.23586261\n",
      "Epoch 79: g_loss: 0.95511329 d_loss: 1.24165893\n",
      "Epoch 80: g_loss: 0.97274113 d_loss: 1.23674119\n",
      "Epoch 81: g_loss: 0.95378792 d_loss: 1.24561846\n",
      "Epoch 82: g_loss: 0.95178264 d_loss: 1.24737370\n",
      "Epoch 83: g_loss: 0.96124339 d_loss: 1.25140655\n",
      "Epoch 84: g_loss: 0.96532327 d_loss: 1.23641026\n",
      "Epoch 85: g_loss: 0.95463437 d_loss: 1.24118340\n",
      "Epoch 86: g_loss: 0.94793618 d_loss: 1.24757111\n",
      "Epoch 87: g_loss: 0.95493937 d_loss: 1.24595284\n",
      "Epoch 88: g_loss: 0.94941378 d_loss: 1.25249219\n",
      "Epoch 89: g_loss: 0.95723218 d_loss: 1.24752736\n",
      "Epoch 90: g_loss: 0.93879914 d_loss: 1.25128376\n",
      "Epoch 91: g_loss: 0.92670399 d_loss: 1.25920546\n",
      "Epoch 92: g_loss: 0.94066465 d_loss: 1.25062120\n",
      "Epoch 93: g_loss: 0.93209189 d_loss: 1.25626302\n",
      "Epoch 94: g_loss: 0.93550164 d_loss: 1.25968683\n",
      "Epoch 95: g_loss: 0.94192123 d_loss: 1.25354207\n",
      "Epoch 96: g_loss: 0.91388643 d_loss: 1.25997472\n",
      "Epoch 97: g_loss: 0.92881548 d_loss: 1.26095057\n",
      "Epoch 98: g_loss: 0.92676872 d_loss: 1.26603746\n",
      "Epoch 99: g_loss: 0.92787397 d_loss: 1.25920463\n",
      "Epoch 100: g_loss: 0.93313378 d_loss: 1.25658441\n",
      "Epoch 101: g_loss: 0.93006247 d_loss: 1.26370168\n",
      "Epoch 102: g_loss: 0.91565657 d_loss: 1.26292205\n",
      "Epoch 103: g_loss: 0.90947580 d_loss: 1.27292717\n",
      "Epoch 104: g_loss: 0.90857321 d_loss: 1.26937115\n",
      "Epoch 105: g_loss: 0.92651767 d_loss: 1.26763070\n",
      "Epoch 106: g_loss: 0.92506063 d_loss: 1.26500654\n",
      "Epoch 107: g_loss: 0.92155141 d_loss: 1.26616621\n",
      "Epoch 108: g_loss: 0.91546893 d_loss: 1.26515567\n",
      "Epoch 109: g_loss: 0.91053528 d_loss: 1.26579714\n",
      "Epoch 110: g_loss: 0.91009015 d_loss: 1.27294886\n",
      "Epoch 111: g_loss: 0.91719973 d_loss: 1.26454151\n",
      "Epoch 112: g_loss: 0.91950530 d_loss: 1.26735961\n",
      "Epoch 113: g_loss: 0.92102540 d_loss: 1.26638865\n",
      "Epoch 114: g_loss: 0.89764059 d_loss: 1.27375376\n",
      "Epoch 115: g_loss: 0.89388043 d_loss: 1.27791142\n",
      "Epoch 116: g_loss: 0.91952497 d_loss: 1.26836801\n",
      "Epoch 117: g_loss: 0.91344178 d_loss: 1.26837552\n",
      "Epoch 118: g_loss: 0.89775681 d_loss: 1.27531505\n",
      "Epoch 119: g_loss: 0.90357202 d_loss: 1.27222764\n",
      "Epoch 120: g_loss: 0.91452610 d_loss: 1.27106726\n",
      "Epoch 121: g_loss: 0.91055906 d_loss: 1.26674926\n",
      "Epoch 122: g_loss: 0.91014606 d_loss: 1.27295899\n",
      "Epoch 123: g_loss: 0.88913906 d_loss: 1.28124261\n",
      "Epoch 124: g_loss: 0.90371394 d_loss: 1.27498412\n",
      "Epoch 125: g_loss: 0.89745390 d_loss: 1.27275205\n",
      "Epoch 126: g_loss: 0.90429044 d_loss: 1.27403629\n",
      "Epoch 127: g_loss: 0.90697986 d_loss: 1.27896440\n",
      "Epoch 128: g_loss: 0.89975989 d_loss: 1.27825034\n",
      "Epoch 129: g_loss: 0.89381057 d_loss: 1.28285825\n",
      "Epoch 130: g_loss: 0.89286017 d_loss: 1.28021538\n",
      "Epoch 131: g_loss: 0.89445037 d_loss: 1.28128099\n",
      "Epoch 132: g_loss: 0.91173053 d_loss: 1.27325523\n",
      "Epoch 133: g_loss: 0.89839602 d_loss: 1.27648616\n",
      "Epoch 134: g_loss: 0.90951371 d_loss: 1.26811934\n",
      "Epoch 135: g_loss: 0.90351075 d_loss: 1.27334845\n",
      "Epoch 136: g_loss: 0.89461631 d_loss: 1.27964389\n",
      "Epoch 137: g_loss: 0.88648123 d_loss: 1.28134048\n",
      "Epoch 138: g_loss: 0.90939367 d_loss: 1.27621591\n",
      "Epoch 139: g_loss: 0.90169531 d_loss: 1.27700567\n",
      "Epoch 140: g_loss: 0.88082016 d_loss: 1.28152454\n",
      "Epoch 141: g_loss: 0.89986533 d_loss: 1.28411126\n",
      "Epoch 142: g_loss: 0.89468473 d_loss: 1.28608620\n",
      "Epoch 143: g_loss: 0.88455427 d_loss: 1.28396642\n",
      "Epoch 144: g_loss: 0.88452965 d_loss: 1.28368831\n",
      "Epoch 145: g_loss: 0.89204979 d_loss: 1.28090131\n",
      "Epoch 146: g_loss: 0.90647924 d_loss: 1.28103364\n",
      "Epoch 147: g_loss: 0.88660771 d_loss: 1.28330386\n",
      "Epoch 148: g_loss: 0.88541377 d_loss: 1.27978826\n",
      "Epoch 149: g_loss: 0.89536077 d_loss: 1.27764547\n",
      "Epoch 150: g_loss: 0.89439267 d_loss: 1.28238761\n",
      "Epoch 151: g_loss: 0.88814265 d_loss: 1.28407001\n",
      "Epoch 152: g_loss: 0.88857663 d_loss: 1.28040731\n",
      "Epoch 153: g_loss: 0.89065987 d_loss: 1.28511572\n",
      "Epoch 154: g_loss: 0.88930249 d_loss: 1.28361583\n",
      "Epoch 155: g_loss: 0.88567984 d_loss: 1.28572643\n",
      "Epoch 156: g_loss: 0.87807000 d_loss: 1.28645480\n",
      "Epoch 157: g_loss: 0.87762654 d_loss: 1.28705430\n",
      "Epoch 158: g_loss: 0.88728517 d_loss: 1.28386867\n",
      "Epoch 159: g_loss: 0.88846433 d_loss: 1.28459525\n",
      "Epoch 160: g_loss: 0.87534654 d_loss: 1.28903592\n",
      "Epoch 161: g_loss: 0.87909693 d_loss: 1.28828549\n",
      "Epoch 162: g_loss: 0.88313162 d_loss: 1.28844821\n",
      "Epoch 163: g_loss: 0.88622856 d_loss: 1.28175104\n",
      "Epoch 164: g_loss: 0.87014788 d_loss: 1.28665054\n",
      "Epoch 165: g_loss: 0.88248980 d_loss: 1.28620970\n",
      "Epoch 166: g_loss: 0.89024872 d_loss: 1.27958953\n",
      "Epoch 167: g_loss: 0.88499594 d_loss: 1.28572536\n",
      "Epoch 168: g_loss: 0.88175964 d_loss: 1.28722477\n",
      "Epoch 169: g_loss: 0.87587416 d_loss: 1.28869629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170: g_loss: 0.88601029 d_loss: 1.29034090\n",
      "Epoch 171: g_loss: 0.88896686 d_loss: 1.28475547\n",
      "Epoch 172: g_loss: 0.87605643 d_loss: 1.29159474\n",
      "Epoch 173: g_loss: 0.87774253 d_loss: 1.28654921\n",
      "Epoch 174: g_loss: 0.88042969 d_loss: 1.28832483\n",
      "Epoch 175: g_loss: 0.87577224 d_loss: 1.28582692\n",
      "Epoch 176: g_loss: 0.88051426 d_loss: 1.28365970\n",
      "Epoch 177: g_loss: 0.87632698 d_loss: 1.29152465\n",
      "Epoch 178: g_loss: 0.88533276 d_loss: 1.28629851\n",
      "Epoch 179: g_loss: 0.87059200 d_loss: 1.29234362\n",
      "Epoch 180: g_loss: 0.87689227 d_loss: 1.28816092\n",
      "Epoch 181: g_loss: 0.87507397 d_loss: 1.28801942\n",
      "Epoch 182: g_loss: 0.88452679 d_loss: 1.28962088\n",
      "Epoch 183: g_loss: 0.87511015 d_loss: 1.29478121\n",
      "Epoch 184: g_loss: 0.87070036 d_loss: 1.29036832\n",
      "Epoch 185: g_loss: 0.86518383 d_loss: 1.29352152\n",
      "Epoch 186: g_loss: 0.87365323 d_loss: 1.29150963\n",
      "Epoch 187: g_loss: 0.87984043 d_loss: 1.29396677\n",
      "Epoch 188: g_loss: 0.87432921 d_loss: 1.29398298\n",
      "Epoch 189: g_loss: 0.87650520 d_loss: 1.28694546\n",
      "Epoch 190: g_loss: 0.88131869 d_loss: 1.28384602\n",
      "Epoch 191: g_loss: 0.86426431 d_loss: 1.29298949\n",
      "Epoch 192: g_loss: 0.86401182 d_loss: 1.29699111\n",
      "Epoch 193: g_loss: 0.87556881 d_loss: 1.28855515\n",
      "Epoch 194: g_loss: 0.87922174 d_loss: 1.29268909\n",
      "Epoch 195: g_loss: 0.88167006 d_loss: 1.29021239\n",
      "Epoch 196: g_loss: 0.88925695 d_loss: 1.28291285\n",
      "Epoch 197: g_loss: 0.87458652 d_loss: 1.28839636\n",
      "Epoch 198: g_loss: 0.87333512 d_loss: 1.28842878\n",
      "Epoch 199: g_loss: 0.86690414 d_loss: 1.29305255\n",
      "Epoch 200: g_loss: 0.86140299 d_loss: 1.29674244\n",
      "Epoch 201: g_loss: 0.88848579 d_loss: 1.28084064\n",
      "Epoch 202: g_loss: 0.87072772 d_loss: 1.29307437\n",
      "Epoch 203: g_loss: 0.87261629 d_loss: 1.28931427\n",
      "Epoch 204: g_loss: 0.86754262 d_loss: 1.29221416\n",
      "Epoch 205: g_loss: 0.86075771 d_loss: 1.29529285\n",
      "Epoch 206: g_loss: 0.86797065 d_loss: 1.29425287\n",
      "Epoch 207: g_loss: 0.86745477 d_loss: 1.28963256\n",
      "Epoch 208: g_loss: 0.87237978 d_loss: 1.29200196\n",
      "Epoch 209: g_loss: 0.89152920 d_loss: 1.28697693\n",
      "Epoch 210: g_loss: 0.87146956 d_loss: 1.29234385\n",
      "Epoch 211: g_loss: 0.87874657 d_loss: 1.29111350\n",
      "Epoch 212: g_loss: 0.87120479 d_loss: 1.29446197\n",
      "Epoch 213: g_loss: 0.86529875 d_loss: 1.29278731\n",
      "Epoch 214: g_loss: 0.88317740 d_loss: 1.29070473\n",
      "Epoch 215: g_loss: 0.87113911 d_loss: 1.29226995\n",
      "Epoch 216: g_loss: 0.86719781 d_loss: 1.29531121\n",
      "Epoch 217: g_loss: 0.86892277 d_loss: 1.29321659\n",
      "Epoch 218: g_loss: 0.87107223 d_loss: 1.29112875\n",
      "Epoch 219: g_loss: 0.87476289 d_loss: 1.29296088\n",
      "Epoch 220: g_loss: 0.87023795 d_loss: 1.29280782\n",
      "Epoch 221: g_loss: 0.85841048 d_loss: 1.29847491\n",
      "Epoch 222: g_loss: 0.87640715 d_loss: 1.29159546\n",
      "Epoch 223: g_loss: 0.87393415 d_loss: 1.29174626\n",
      "Epoch 224: g_loss: 0.86581153 d_loss: 1.29457188\n",
      "Epoch 225: g_loss: 0.86016470 d_loss: 1.29656458\n",
      "Epoch 226: g_loss: 0.87247849 d_loss: 1.29181254\n",
      "Epoch 227: g_loss: 0.86534578 d_loss: 1.29726756\n",
      "Epoch 228: g_loss: 0.87260109 d_loss: 1.29264903\n",
      "Epoch 229: g_loss: 0.87627876 d_loss: 1.29450476\n",
      "Epoch 230: g_loss: 0.88219887 d_loss: 1.28843713\n",
      "Epoch 231: g_loss: 0.85899502 d_loss: 1.29681373\n",
      "Epoch 232: g_loss: 0.86827880 d_loss: 1.29306173\n",
      "Epoch 233: g_loss: 0.87480730 d_loss: 1.29250276\n",
      "Epoch 234: g_loss: 0.86877531 d_loss: 1.29478407\n",
      "Epoch 235: g_loss: 0.87096822 d_loss: 1.29413188\n",
      "Epoch 236: g_loss: 0.87158012 d_loss: 1.29086304\n",
      "Epoch 237: g_loss: 0.86777592 d_loss: 1.29690480\n",
      "Epoch 238: g_loss: 0.87084371 d_loss: 1.29123271\n",
      "Epoch 239: g_loss: 0.87715775 d_loss: 1.29011619\n",
      "Epoch 240: g_loss: 0.87112880 d_loss: 1.28993428\n",
      "Epoch 241: g_loss: 0.86355931 d_loss: 1.29438853\n",
      "Epoch 242: g_loss: 0.86423212 d_loss: 1.29535663\n",
      "Epoch 243: g_loss: 0.87168229 d_loss: 1.29746783\n",
      "Epoch 244: g_loss: 0.86481649 d_loss: 1.29206169\n",
      "Epoch 245: g_loss: 0.86415660 d_loss: 1.29482675\n",
      "Epoch 246: g_loss: 0.87022573 d_loss: 1.29902494\n",
      "Epoch 247: g_loss: 0.87592900 d_loss: 1.29178095\n",
      "Epoch 248: g_loss: 0.85896516 d_loss: 1.29670477\n",
      "Epoch 249: g_loss: 0.84928650 d_loss: 1.30518234\n",
      "Training Finished\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 250\n",
    "k = 1\n",
    "test_noise = noise(64)\n",
    "\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "for epoch in range(num_epochs):\n",
    "    g_error = 0.0\n",
    "    d_error = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        imgs, _ = data\n",
    "        n = len(imgs)\n",
    "        for j in range(k):\n",
    "            fake_data = generator(noise(n)).detach()\n",
    "            real_data = imgs.to(device)\n",
    "            d_error += train_discriminator(d_optim, real_data, fake_data)\n",
    "        fake_data = generator(noise(n))\n",
    "        g_error += train_generator(g_optim, fake_data)\n",
    "\n",
    "    img = generator(test_noise).cpu().detach()\n",
    "    img = make_grid(img)\n",
    "    images.append(img)\n",
    "    g_losses.append(g_error/i)\n",
    "    d_losses.append(d_error/i)\n",
    "    print('Epoch {}: g_loss: {:.8f} d_loss: {:.8f}\\r'.format(epoch, g_error/i, d_error/i))\n",
    "    \n",
    "print('Training Finished')\n",
    "torch.save(generator.state_dict(), 'mnist_generator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c76b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13333a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d70d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c7ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d284eecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
