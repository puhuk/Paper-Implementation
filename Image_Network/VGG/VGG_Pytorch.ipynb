{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG_PyTorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs2nYBm2B2DW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "ceeb6342-0737-4a16-8720-79528c4280a2"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My Drive/Colab Notebooks/VGG/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Colab Notebooks/VGG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWJFINbgn8J2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing required libraries\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kOF9hvTn8Nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(VGG16, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "#         self.bn1 = nn.BatchNorm2d(64)\n",
        "#         self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(64,64, kernel_size=3, padding=1)\n",
        "        self.maxPool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(64,128, kernel_size=3, padding=1)\n",
        "        #self.bn2 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(128,128, kernel_size=3, padding=1)\n",
        "        \n",
        "        self.conv5 = nn.Conv2d(128,256, kernel_size=3, padding=1)\n",
        "        #self.bn3 = nn.BatchNorm2d(256)\n",
        "        \n",
        "        self.conv6 = nn.Conv2d(256,256, kernel_size=3, padding=1)\n",
        "        self.conv7 = nn.Conv2d(256,256, kernel_size=1, padding=0)\n",
        "        \n",
        "        self.conv8 = nn.Conv2d(256,512, kernel_size=3, padding=1)\n",
        "        #self.bn4 = nn.BatchNorm2d(512)\n",
        "        \n",
        "        self.conv9 = nn.Conv2d(512,512, kernel_size=3, padding=1)\n",
        "        self.conv10 = nn.Conv2d(512,512, kernel_size=1, padding=0)\n",
        "        \n",
        "        self.conv11 = nn.Conv2d(512,512, kernel_size=3, padding=1)\n",
        "        self.conv12 = nn.Conv2d(512,512, kernel_size=3, padding=1)\n",
        "        self.conv13 = nn.Conv2d(512,512, kernel_size=1, padding=0)\n",
        "        \n",
        "        self.linear1 = nn.Linear(512*7*7, 4096)\n",
        "        self.linear2 = nn.Linear(4096, 4096)\n",
        "        self.linear3 = nn.Linear(4096, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out= self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.maxPool(out)\n",
        "        \n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.maxPool(out)\n",
        "        \n",
        "        out = self.conv5(out)\n",
        "        out = self.conv6(out)\n",
        "        out = self.conv7(out)\n",
        "        out = self.maxPool(out)\n",
        "        \n",
        "        out = self.conv8(out)\n",
        "        out = self.conv9(out)\n",
        "        out = self.conv10(out)\n",
        "        out = self.maxPool(out)\n",
        "        \n",
        "        out = self.conv11(out)\n",
        "        out = self.conv12(out)\n",
        "        out = self.conv13(out)\n",
        "\n",
        "        out = self.maxPool(out)\n",
        "        \n",
        "        out = out.view(out.size(0),-1)\n",
        "        out = self.linear1(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.linear3(out)\n",
        "        \n",
        "        return out\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgLKov5Ln8Qr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cddcbf01-a81e-4552-b40d-a8364df27b71"
      },
      "source": [
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "dataset_train = CIFAR10(root='../data', train=True, \n",
        "            download=True, transform=transform)\n",
        "dataset_test = CIFAR10(root='../data', train=False, \n",
        "             download=True, transform=transform)\n",
        "train_loader = DataLoader(dataset_train, batch_size=32, \n",
        "                        shuffle=True)\n",
        "test_loader = DataLoader(dataset_test, batch_size=32, \n",
        "                       shuffle=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C9wkI5tn8UU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=VGG16()\n",
        "model=model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-m0agGTw2l2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterio=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0005)\n",
        "device=torch.device('cuda')\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "NUM_EPOCHS=100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41LqnrY1w6iN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18900ff4-cfe2-4279-d6ed-c8f25731aaf0"
      },
      "source": [
        "model.train()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  for imgs, classes in train_loader:\n",
        "    #print(imgs.shape, classes.shape)\n",
        "    imgs, classes=imgs.to(device), classes.to(device)\n",
        "    outputs = model(imgs)\n",
        "\n",
        "    loss = criterio(outputs, classes)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    #print(loss.item())\n",
        "    #print(preds)\n",
        "\n",
        "  if epoch%10 == 0:\n",
        "      print('Epoch {}: Loss = {} Accuracy = {} '.format(epoch+1, loss.item(),torch.sum(preds == classes).item()/32))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: Loss = 602881916928.0 Accuracy = 0.03125 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUwRPxJWn8XU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "outputId": "3463adb9-4e33-4809-adce-9d004a5a1264"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model=model.to(device)\n",
        "\n",
        "for i, (input_,target) in enumerate(train_loader):\n",
        "    target = target.to(device)\n",
        "    input_ = input_.to(device)\n",
        "    print(input_.shape)\n",
        "    print(target.shape, input_.shape)\n",
        "\n",
        "    output = model(input_)\n",
        "    loss = criterio(output,target)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if(i%20 == 0):\n",
        "        print(\"loss in epoch %d , step %d : %f\" % (epoch, i,loss.data[0]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 3, 224, 224])\n",
            "torch.Size([32]) torch.Size([32, 3, 224, 224])\n",
            "torch.Size([32, 64, 224, 224])\n",
            "torch.Size([32, 64, 224, 224])\n",
            "torch.Size([32, 64, 112, 112])\n",
            "torch.Size([32, 128, 112, 112])\n",
            "torch.Size([32, 128, 112, 112])\n",
            "torch.Size([32, 128, 56, 56])\n",
            "torch.Size([32, 256, 56, 56])\n",
            "torch.Size([32, 256, 56, 56])\n",
            "torch.Size([32, 256, 56, 56])\n",
            "torch.Size([32, 256, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 28, 28])\n",
            "torch.Size([32, 512, 14, 14])\n",
            "torch.Size([32, 512, 14, 14])\n",
            "torch.Size([32, 512, 14, 14])\n",
            "torch.Size([32, 512, 14, 14])\n",
            "torch.Size([32, 512, 7, 7])\n",
            "torch.Size([32, 25088])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c468915a3da1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'criterion' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-znOI7bmn8aM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7__H_uo3n8cj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}