{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "SegNet_Pytorch.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXCZRSSgIZgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing required libraries\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0211ewPgImqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "a16ac067-0db4-425a-dcfd-3a1439998941"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My Drive/Colab Notebooks/Segnet/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Colab Notebooks/Segnet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPGU1iC9I4MT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqlRi5cVIZgQ",
        "colab_type": "text"
      },
      "source": [
        "[!img]segnet.png"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uN-Zbe7IZgR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SegNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SegNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(64,64, kernel_size=3, padding=1)\n",
        "                \n",
        "        self.conv3 = nn.Conv2d(64,128, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(128,128, kernel_size=3, padding=1)\n",
        "        \n",
        "        self.conv5 = nn.Conv2d(128,256, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        \n",
        "        self.conv6 = nn.Conv2d(256,256, kernel_size=3, padding=1)\n",
        "        \n",
        "        self.conv7 = nn.Conv2d(256,512, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "        \n",
        "        self.conv8 = nn.Conv2d(512,512, kernel_size=3, padding=1)        \n",
        "        \n",
        "        self.upSample = nn.MaxUnpool2d(2, stride=2)\n",
        "      \n",
        "        self.decode1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.decode2 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
        "        self.dec_bn1 = nn.BatchNorm2d(512)\n",
        "        self.dec_relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.dec_bn2 = nn.BatchNorm2d(256)\n",
        "        \n",
        "        self.decode3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.decode4 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
        "        self.dec_bn3 = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.decode5 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.decode6 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
        "        self.dec_bn4 = nn.BatchNorm2d(64)\n",
        "        self.decode7 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        \n",
        "        self.decode8 = nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        out= self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        x1p, id1 = F.max_pool2d(out,kernel_size=2, stride=2,return_indices=True)\n",
        "        \n",
        "        out = self.conv3(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.maxPool(out)\n",
        "        x2p, id2 = F.max_pool2d(out,kernel_size=2, stride=2,return_indices=True)\n",
        "                \n",
        "        out = self.conv5(out)\n",
        "        out = self.bn3(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv6(out)\n",
        "        out = self.bn3(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv6(out)\n",
        "        out = self.bn3(out)\n",
        "        out = self.relu(out)\n",
        "        x3p, id3 = F.max_pool2d(out,kernel_size=2, stride=2,return_indices=True)\n",
        "        \n",
        "        out = self.conv7(out)\n",
        "        out = self.bn4(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv8(out)\n",
        "        out = self.bn4(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv8(out)\n",
        "        out = self.bn4(out)\n",
        "        out = self.relu(out)\n",
        "        x4p, id4 = F.max_pool2d(out,kernel_size=2, stride=2,return_indices=True)\n",
        "        \n",
        "        out = self.conv8(out)\n",
        "        out = self.bn5(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv8(out)\n",
        "        out = self.bn5(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv8(out)\n",
        "        out = self.bn5(out)\n",
        "        out = self.relu(out)\n",
        "        x5p, id5 = F.max_pool2d(out,kernel_size=2, stride=2,return_indices=True)\n",
        "        \n",
        "        out = self.upSample(x5p, id5)\n",
        "        out = self.decode1(out)\n",
        "        out = self.dec_bn1(out)\n",
        "        out = self.dec_relu(out)\n",
        "        out = self.decode1(out)\n",
        "        out = self.dec_bn1(out)\n",
        "        out = self.dec_relu(out)\n",
        "        out = self.decode1(out)\n",
        "        out = self.dec_bn1(out)\n",
        "        out = self.dec_relu(out)\n",
        "        \n",
        "        out = self.upSample(out, id4)\n",
        "        out = self.decode1(out)\n",
        "        out = self.dec_bn1(out)\n",
        "        out = self.dec_relu(out)\n",
        "        out = self.decode1(out)\n",
        "        out = self.dec_bn1(out)\n",
        "        out = self.dec_relu(out)\n",
        "        out = self.decode2(out)\n",
        "        out = self.dec_bn2(out)\n",
        "        out = self.dec_relu(out)\n",
        "        \n",
        "        out = self.upSample(out, id3)\n",
        "        out = self.decode3(out)\n",
        "        out = self.dec_bn2(out)\n",
        "        out = self.dec_relu(out)\n",
        "        out = self.decode3(out)\n",
        "        out = self.dec_bn2(out)\n",
        "        out = self.dec_relu(out)\n",
        "        out = self.decode4(out)\n",
        "        out = self.dec_bn3(out)\n",
        "        out = self.dec_relu(out)\n",
        "        \n",
        "        out = self.upSample(out, id2)\n",
        "        out = self.decode5(out)\n",
        "        out = self.dec_bn3(out)\n",
        "        out = self.dec_relu(out)\n",
        "        out = self.decode6(out)\n",
        "        out = self.dec_bn4(out)\n",
        "        out = self.dec_relu(out)\n",
        "        \n",
        "        out = self.upSample(out, id1)\n",
        "        out = self.decode7(out)\n",
        "        out = self.dec_bn4(out)\n",
        "        out = self.dec_relu(out)\n",
        "        out = self.decode8(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k1mCo5iIZgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SegNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOmCHAYcIZgZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "7b7831e0-6f97-422f-bb60-53ac536f5830"
      },
      "source": [
        "model"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SegNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (upSample): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
              "  (decode1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (decode2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (dec_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dec_relu): ReLU(inplace=True)\n",
              "  (dec_bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (decode3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (decode4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (dec_bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (decode5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (decode6): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (dec_bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (decode7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (decode8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLgSF3OcIZgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "import numpy as np\n",
        "import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdI_k0d5IZgg",
        "colab_type": "text"
      },
      "source": [
        "### Data preparation w/ VOC2012"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GMCF4viIZgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_img=[]\n",
        "train_mask=[]\n",
        "trainval_img=[]\n",
        "trainval_mask=[]\n",
        "val_img=[]\n",
        "val_mask=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQyokZbdJgTG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "7289cd17-29f3-4693-c874-5be5affc1811"
      },
      "source": [
        "import os\n",
        "os.listdir(\"../VOC_2011/\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a5d115e3b3f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../VOC_2011/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../VOC_2011/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpryzsLLIZgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data.dataset import Dataset  # For custom data-sets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "PATH = \"../VOC2011/\"\n",
        "#train = open(PATH +\"../Data/ImageSets/Segmentation/train.txt\", 'r')\n",
        "train = open(PATH +\"ImageSets/Segmentation/train.txt\", 'r')\n",
        "lines = train.readlines()\n",
        "for i, line in enumerate(lines):\n",
        "    train_img.append(PATH +\"JPEGImages/\"+line.split('\\n')[0]+\".jpg\")\n",
        "    train_mask.append(PATH + \"SegmentationClass/\" + line.split('\\n')[0] + \".png\")\n",
        "train.close()\n",
        "\n",
        "trainval = open(PATH +\"ImageSets/Segmentation/trainval.txt\", 'r')\n",
        "lines = trainval.readlines()\n",
        "for i, line in enumerate(lines):\n",
        "    train_img.append(PATH +\"JPEGImages/\"+line.split('\\n')[0]+\".jpg\")\n",
        "    train_mask.append(PATH + \"SegmentationClass/\"+line.split('\\n')[0]+\".png\")\n",
        "trainval.close()\n",
        "\n",
        "val = open(PATH +\"ImageSets/Segmentation/val.txt\", 'r')\n",
        "lines = val.readlines()\n",
        "for i, line in enumerate(lines):\n",
        "    val_img.append(PATH +\"JPEGImages/\"+line.split('\\n')[0]+\".jpg\")\n",
        "    val_mask.append(PATH +\"SegmentationClass/\"+line.split('\\n')[0]+\".png\")\n",
        "val.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8kb4GcRIZgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, target_paths, train=True):   # initial logic happens like transform\n",
        "        self.image_paths = image_paths\n",
        "        self.target_paths = target_paths\n",
        "        self.transforms = transforms.ToTensor()\n",
        "        \n",
        "    def transform(self, image, mask):\n",
        "        resize=transforms.Resize(size=(520,520))\n",
        "        image=resize(image)\n",
        "        mask=resize(mask)\n",
        "        \n",
        "        # Random crop\n",
        "        i, j, h, w = transforms.RandomCrop.get_params(\n",
        "            image, output_size=(512, 512))\n",
        "        image = TF.crop(image, i, j, h, w)\n",
        "        mask = TF.crop(mask, i, j, h, w)\n",
        "\n",
        "        # Random horizontal flipping\n",
        "        num=random.random()\n",
        "        if num > 0.5:\n",
        "            image = TF.hflip(image)\n",
        "            mask = TF.hflip(mask)\n",
        "\n",
        "        # Random vertical flipping\n",
        "        if num > 0.5:\n",
        "            image = TF.vflip(image)\n",
        "            mask = TF.vflip(mask)\n",
        "\n",
        "         # Transform to tensor\n",
        "        image = TF.to_tensor(image)\n",
        "        mask = TF.to_tensor(mask)\n",
        "\n",
        "        mean=[0.4546, 0.4405, 0.4051]\n",
        "        std=[0.2322, 0.2282, 0.2337]\n",
        "        image[0]=(image[0]-mean[0])/std[0]\n",
        "        image[1]=(image[1]-mean[1])/std[1]\n",
        "        image[2]=(image[2]-mean[2])/std[2]\n",
        "        \n",
        "        return image, mask\n",
        "    \n",
        "    \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        image = Image.open(self.image_paths[index]).convert(\"RGB\")\n",
        "        mask = Image.open(self.target_paths[index]).convert(\"P\")\n",
        "\n",
        "        image, label=self.transform(image, mask)\n",
        "        \n",
        "        label_size=label.size\n",
        "        \n",
        "        # One-hot encoding \n",
        "        h = label.shape[1]\n",
        "        w= label.shape[2]\n",
        "        target = torch.zeros(21, h, w)\n",
        "        \n",
        "        label.reshape((-1,2))\n",
        "        for c in range(21):\n",
        "            target[c][label[0] == c] = 1\n",
        "\n",
        "        return {'x': image, 'y':target, 'l':label[0]} \n",
        "\n",
        "        \n",
        "\n",
        "    def __len__(self):  # return count of sample we have\n",
        "        return len(self.image_paths)\n",
        "\n",
        "\n",
        "train_dataset = CustomDataset(train_img, train_mask, train=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "trainval_dataset = CustomDataset(trainval_img, trainval_mask, train=False)\n",
        "trainval_loader = torch.utils.data.DataLoader(trainval_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "val_dataset = CustomDataset(val_img, val_mask, train=False)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj31fmqeIZgq",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22jCkK3FIZgr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "320586a3-7803-4adc-b7ec-a5856dc13596"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          \n",
        "    \n",
        "import random\n",
        "for i, batch in enumerate(train_loader):\n",
        "    print(i, batch['x'].shape, batch['y'].shape, batch['l'].shape)\n",
        "    break"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 torch.Size([8, 3, 512, 512]) torch.Size([8, 21, 512, 512]) torch.Size([8, 512, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYSqx8B9J2Ds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFltld7FIZgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best = 0\n",
        "meaniou=100\n",
        "epochs=100\n",
        "# model = model.to(device)\n",
        "for epoch in range(epochs):\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        # inputs, labels = batch['x'].to(device), batch['y'].to(device)\n",
        "        inputs, labels = batch['x'], batch['y']\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model.forward(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if i % print_every == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                #paccuracy, meaniou = validation(model, validloader, criterion)\n",
        "                print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
        "                      \"Training loss: {:.5f}.. \".format(loss.item()))\n",
        "            if best < meaniou:\n",
        "                torch.save(model.state_dict(), \"./segnet.pth\")\n",
        "                best = meaniou\n",
        "            model.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tvFk4QZIZgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HbKBMrdIZg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkTiSBQmIZg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02L_ii8qIZg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY3aIkgoIZg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrnhiYaQIZhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDRKjA4JIZhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}