{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input, LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_VOCAB_SIZE = 3000\n",
    "EMBEDDING_DIM = 50\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "LATENT_DIM = 25\n",
    "\n",
    "input_texts = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length: 12\n",
      "Found 3056 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# load in the data\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "for line in open('robert_frost.txt', encoding='UTF-8'):\n",
    "    line = line.rstrip()\n",
    "    \n",
    "    if not line:\n",
    "        continue\n",
    "\n",
    "    input_line = '<sos> ' + line\n",
    "    \n",
    "    target_line = line + ' <eos>'\n",
    "    input_texts.append(input_line)\n",
    "    target_texts.append(target_line)\n",
    "\n",
    "all_lines = input_texts + target_texts\n",
    "\n",
    "# convert the sentences (strings) into integers\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
    "tokenizer.fit_on_texts(all_lines)\n",
    "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "target_sequences = tokenizer.texts_to_sequences(target_texts)\n",
    "\n",
    "# find max seq length\n",
    "max_sequence_length_from_data = max(len(s) for s in input_sequences)\n",
    "print('Max sequence length:', max_sequence_length_from_data)\n",
    "\n",
    "# get word -> integer mapping\n",
    "word2idx = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word2idx))\n",
    "assert('<sos>' in word2idx)\n",
    "assert('<eos>' in word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glove.6B.50d.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join('glove.6B.%sd.txt' % EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (1436, 12)\n",
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# pad sequences so that we get a N x T matrix\n",
    "max_sequence_length = min(max_sequence_length_from_data, MAX_SEQUENCE_LENGTH)\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='post')\n",
    "target_sequences = pad_sequences(target_sequences, maxlen=max_sequence_length, padding='post')\n",
    "print('Shape of data tensor:', input_sequences.shape)\n",
    "\n",
    "# load in pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open('../glove.6B/'+os.path.join('glove.6B.%sd.txt' % EMBEDDING_DIM), encoding='UTF-8') as f:\n",
    "    # is just a space-separated text file in the format:\n",
    "    # word vec[0] vec[1] vec[2] ...\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "\n",
    "print('Found %s word vectors.' % len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word2idx.items():\n",
    "    if i < MAX_VOCAB_SIZE:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot the targets (can't use sparse cross-entropy)\n",
    "\n",
    "one_hot_targets = np.zeros((len(input_sequences), max_sequence_length, num_words))\n",
    "\n",
    "for i, target_sequence in enumerate(target_sequences):\n",
    "    for t, word in enumerate(target_sequence):\n",
    "        if word > 0:\n",
    "            one_hot_targets[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained word embeddings into an Embedding layer\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  # trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Training model...\n",
      "Train on 1148 samples, validate on 288 samples\n",
      "Epoch 1/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 5.3813 - accuracy: 0.0637 - val_loss: 5.0157 - val_accuracy: 0.0457\n",
      "Epoch 2/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 4.4821 - accuracy: 0.0592 - val_loss: 4.6569 - val_accuracy: 0.0830\n",
      "Epoch 3/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 4.1243 - accuracy: 0.0833 - val_loss: 4.6460 - val_accuracy: 0.0833\n",
      "Epoch 4/100\n",
      "1148/1148 [==============================] - 4s 4ms/step - loss: 3.9922 - accuracy: 0.0833 - val_loss: 4.6367 - val_accuracy: 0.0833\n",
      "Epoch 5/100\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.8860 - accuracy: 0.0833 - val_loss: 4.6420 - val_accuracy: 0.0828\n",
      "Epoch 6/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 3.7925 - accuracy: 0.0840 - val_loss: 4.6445 - val_accuracy: 0.0845\n",
      "Epoch 7/100\n",
      "1148/1148 [==============================] - 4s 4ms/step - loss: 3.7025 - accuracy: 0.0865 - val_loss: 4.6355 - val_accuracy: 0.0848\n",
      "Epoch 8/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 3.6151 - accuracy: 0.0928 - val_loss: 4.6304 - val_accuracy: 0.0883\n",
      "Epoch 9/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 3.5282 - accuracy: 0.1026 - val_loss: 4.6220 - val_accuracy: 0.0897\n",
      "Epoch 10/100\n",
      "1148/1148 [==============================] - 4s 4ms/step - loss: 3.4488 - accuracy: 0.1071 - val_loss: 4.6235 - val_accuracy: 0.0920\n",
      "Epoch 11/100\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.3724 - accuracy: 0.1230 - val_loss: 4.6290 - val_accuracy: 0.0940\n",
      "Epoch 12/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 3.3004 - accuracy: 0.1380 - val_loss: 4.6408 - val_accuracy: 0.0958\n",
      "Epoch 13/100\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 3.2312 - accuracy: 0.1490 - val_loss: 4.6481 - val_accuracy: 0.0964\n",
      "Epoch 14/100\n",
      "1148/1148 [==============================] - 4s 4ms/step - loss: 3.1651 - accuracy: 0.1587 - val_loss: 4.6640 - val_accuracy: 0.0961\n",
      "Epoch 15/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 3.0995 - accuracy: 0.1624 - val_loss: 4.6763 - val_accuracy: 0.0958\n",
      "Epoch 16/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 3.0382 - accuracy: 0.1696 - val_loss: 4.6881 - val_accuracy: 0.0990\n",
      "Epoch 17/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.9783 - accuracy: 0.1749 - val_loss: 4.7104 - val_accuracy: 0.0964\n",
      "Epoch 18/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 2.9206 - accuracy: 0.1805 - val_loss: 4.7239 - val_accuracy: 0.0964\n",
      "Epoch 19/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.8647 - accuracy: 0.1882 - val_loss: 4.7385 - val_accuracy: 0.0961\n",
      "Epoch 20/100\n",
      "1148/1148 [==============================] - 4s 4ms/step - loss: 2.8118 - accuracy: 0.1951 - val_loss: 4.7578 - val_accuracy: 0.0943\n",
      "Epoch 21/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.7600 - accuracy: 0.1990 - val_loss: 4.7830 - val_accuracy: 0.0949\n",
      "Epoch 22/100\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 2.7111 - accuracy: 0.2024 - val_loss: 4.8019 - val_accuracy: 0.0940\n",
      "Epoch 23/100\n",
      "1148/1148 [==============================] - 8s 7ms/step - loss: 2.6643 - accuracy: 0.2071 - val_loss: 4.8159 - val_accuracy: 0.0897\n",
      "Epoch 24/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 2.6190 - accuracy: 0.2120 - val_loss: 4.8395 - val_accuracy: 0.0900\n",
      "Epoch 25/100\n",
      "1148/1148 [==============================] - 6s 5ms/step - loss: 2.5756 - accuracy: 0.2170 - val_loss: 4.8647 - val_accuracy: 0.0911\n",
      "Epoch 26/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 2.5351 - accuracy: 0.2215 - val_loss: 4.8844 - val_accuracy: 0.0894\n",
      "Epoch 27/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.4945 - accuracy: 0.2268 - val_loss: 4.9008 - val_accuracy: 0.0903\n",
      "Epoch 28/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 2.4567 - accuracy: 0.2319 - val_loss: 4.9238 - val_accuracy: 0.0906\n",
      "Epoch 29/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.4196 - accuracy: 0.2381 - val_loss: 4.9489 - val_accuracy: 0.0888\n",
      "Epoch 30/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 2.3858 - accuracy: 0.2422 - val_loss: 4.9664 - val_accuracy: 0.0888\n",
      "Epoch 31/100\n",
      "1148/1148 [==============================] - 2s 2ms/step - loss: 2.3517 - accuracy: 0.2482 - val_loss: 4.9876 - val_accuracy: 0.0888\n",
      "Epoch 32/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 2.3190 - accuracy: 0.2523 - val_loss: 5.0081 - val_accuracy: 0.0865\n",
      "Epoch 33/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 2.2883 - accuracy: 0.2566 - val_loss: 5.0285 - val_accuracy: 0.0877\n",
      "Epoch 34/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 2.2579 - accuracy: 0.2601 - val_loss: 5.0494 - val_accuracy: 0.0859\n",
      "Epoch 35/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 2.2303 - accuracy: 0.2636 - val_loss: 5.0685 - val_accuracy: 0.0862\n",
      "Epoch 36/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 2.2027 - accuracy: 0.2676 - val_loss: 5.0921 - val_accuracy: 0.0830\n",
      "Epoch 37/100\n",
      "1148/1148 [==============================] - 2s 2ms/step - loss: 2.1761 - accuracy: 0.2698 - val_loss: 5.1134 - val_accuracy: 0.0854\n",
      "Epoch 38/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 2.1516 - accuracy: 0.2738 - val_loss: 5.1285 - val_accuracy: 0.0848\n",
      "Epoch 39/100\n",
      "1148/1148 [==============================] - 2s 2ms/step - loss: 2.1281 - accuracy: 0.2768 - val_loss: 5.1532 - val_accuracy: 0.0845\n",
      "Epoch 40/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 2.1045 - accuracy: 0.2801 - val_loss: 5.1755 - val_accuracy: 0.0833\n",
      "Epoch 41/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 2.0830 - accuracy: 0.2845 - val_loss: 5.1926 - val_accuracy: 0.0833\n",
      "Epoch 42/100\n",
      "1148/1148 [==============================] - 2s 2ms/step - loss: 2.0617 - accuracy: 0.2875 - val_loss: 5.2136 - val_accuracy: 0.0825\n",
      "Epoch 43/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 2.0400 - accuracy: 0.2904 - val_loss: 5.2290 - val_accuracy: 0.0825\n",
      "Epoch 44/100\n",
      "1148/1148 [==============================] - 2s 2ms/step - loss: 2.0202 - accuracy: 0.2926 - val_loss: 5.2465 - val_accuracy: 0.0819\n",
      "Epoch 45/100\n",
      "1148/1148 [==============================] - 2s 2ms/step - loss: 2.0010 - accuracy: 0.2964 - val_loss: 5.2663 - val_accuracy: 0.0836\n",
      "Epoch 46/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.9850 - accuracy: 0.2979 - val_loss: 5.2855 - val_accuracy: 0.0810\n",
      "Epoch 47/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 1.9665 - accuracy: 0.3006 - val_loss: 5.2982 - val_accuracy: 0.0825\n",
      "Epoch 48/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.9485 - accuracy: 0.3042 - val_loss: 5.3176 - val_accuracy: 0.0828\n",
      "Epoch 49/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.9327 - accuracy: 0.3065 - val_loss: 5.3354 - val_accuracy: 0.0796\n",
      "Epoch 50/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.9165 - accuracy: 0.3088 - val_loss: 5.3539 - val_accuracy: 0.0802\n",
      "Epoch 51/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.9007 - accuracy: 0.3109 - val_loss: 5.3708 - val_accuracy: 0.0799\n",
      "Epoch 52/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.8860 - accuracy: 0.3129 - val_loss: 5.3856 - val_accuracy: 0.0784\n",
      "Epoch 53/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 1.8711 - accuracy: 0.3153 - val_loss: 5.3969 - val_accuracy: 0.0825\n",
      "Epoch 54/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.8570 - accuracy: 0.3185 - val_loss: 5.4165 - val_accuracy: 0.0802\n",
      "Epoch 55/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.8419 - accuracy: 0.3203 - val_loss: 5.4301 - val_accuracy: 0.0790\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.8295 - accuracy: 0.3230 - val_loss: 5.4461 - val_accuracy: 0.0784\n",
      "Epoch 57/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 1.8149 - accuracy: 0.3254 - val_loss: 5.4610 - val_accuracy: 0.0816\n",
      "Epoch 58/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.8022 - accuracy: 0.3272 - val_loss: 5.4801 - val_accuracy: 0.0775\n",
      "Epoch 59/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.7887 - accuracy: 0.3298 - val_loss: 5.4917 - val_accuracy: 0.0781\n",
      "Epoch 60/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.7765 - accuracy: 0.3324 - val_loss: 5.5156 - val_accuracy: 0.0816\n",
      "Epoch 61/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.7634 - accuracy: 0.3342 - val_loss: 5.5275 - val_accuracy: 0.0790\n",
      "Epoch 62/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.7517 - accuracy: 0.3362 - val_loss: 5.5330 - val_accuracy: 0.0804\n",
      "Epoch 63/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.7411 - accuracy: 0.3378 - val_loss: 5.5569 - val_accuracy: 0.0787\n",
      "Epoch 64/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.7289 - accuracy: 0.3394 - val_loss: 5.5673 - val_accuracy: 0.0770\n",
      "Epoch 65/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.7174 - accuracy: 0.3415 - val_loss: 5.5816 - val_accuracy: 0.0773\n",
      "Epoch 66/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.7061 - accuracy: 0.3443 - val_loss: 5.5955 - val_accuracy: 0.0775\n",
      "Epoch 67/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.6961 - accuracy: 0.3441 - val_loss: 5.6076 - val_accuracy: 0.0796\n",
      "Epoch 68/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.6841 - accuracy: 0.3469 - val_loss: 5.6264 - val_accuracy: 0.0758\n",
      "Epoch 69/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 1.6730 - accuracy: 0.3492 - val_loss: 5.6325 - val_accuracy: 0.0790\n",
      "Epoch 70/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.6633 - accuracy: 0.3510 - val_loss: 5.6501 - val_accuracy: 0.0767\n",
      "Epoch 71/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.6544 - accuracy: 0.3526 - val_loss: 5.6663 - val_accuracy: 0.0761\n",
      "Epoch 72/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.6438 - accuracy: 0.3543 - val_loss: 5.6793 - val_accuracy: 0.0752\n",
      "Epoch 73/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.6352 - accuracy: 0.3545 - val_loss: 5.6951 - val_accuracy: 0.0752\n",
      "Epoch 74/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 1.6254 - accuracy: 0.3575 - val_loss: 5.7135 - val_accuracy: 0.0738\n",
      "Epoch 75/100\n",
      "1148/1148 [==============================] - 7s 6ms/step - loss: 1.6153 - accuracy: 0.3581 - val_loss: 5.7214 - val_accuracy: 0.0755\n",
      "Epoch 76/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 1.6050 - accuracy: 0.3612 - val_loss: 5.7331 - val_accuracy: 0.0758\n",
      "Epoch 77/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 1.5956 - accuracy: 0.3634 - val_loss: 5.7443 - val_accuracy: 0.0758\n",
      "Epoch 78/100\n",
      "1148/1148 [==============================] - 3s 2ms/step - loss: 1.5873 - accuracy: 0.3651 - val_loss: 5.7574 - val_accuracy: 0.0735\n",
      "Epoch 79/100\n",
      "1148/1148 [==============================] - 4s 4ms/step - loss: 1.5787 - accuracy: 0.3653 - val_loss: 5.7674 - val_accuracy: 0.0729\n",
      "Epoch 80/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 1.5714 - accuracy: 0.3661 - val_loss: 5.7820 - val_accuracy: 0.0755\n",
      "Epoch 81/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 1.5617 - accuracy: 0.3685 - val_loss: 5.8012 - val_accuracy: 0.0735\n",
      "Epoch 82/100\n",
      "1148/1148 [==============================] - 5s 5ms/step - loss: 1.5525 - accuracy: 0.3704 - val_loss: 5.8143 - val_accuracy: 0.0738\n",
      "Epoch 83/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 1.5431 - accuracy: 0.3735 - val_loss: 5.8257 - val_accuracy: 0.0732\n",
      "Epoch 84/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 1.5349 - accuracy: 0.3746 - val_loss: 5.8358 - val_accuracy: 0.0718\n",
      "Epoch 85/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 1.5278 - accuracy: 0.3758 - val_loss: 5.8511 - val_accuracy: 0.0715\n",
      "Epoch 86/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 1.5204 - accuracy: 0.3771 - val_loss: 5.8623 - val_accuracy: 0.0729\n",
      "Epoch 87/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 1.5113 - accuracy: 0.3792 - val_loss: 5.8714 - val_accuracy: 0.0715\n",
      "Epoch 88/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 1.5035 - accuracy: 0.3810 - val_loss: 5.8890 - val_accuracy: 0.0712\n",
      "Epoch 89/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 1.4963 - accuracy: 0.3818 - val_loss: 5.9018 - val_accuracy: 0.0715\n",
      "Epoch 90/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 1.4886 - accuracy: 0.3841 - val_loss: 5.9116 - val_accuracy: 0.0720\n",
      "Epoch 91/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 1.4815 - accuracy: 0.3828 - val_loss: 5.9181 - val_accuracy: 0.0709\n",
      "Epoch 92/100\n",
      "1148/1148 [==============================] - 4s 4ms/step - loss: 1.4744 - accuracy: 0.3859 - val_loss: 5.9381 - val_accuracy: 0.0697\n",
      "Epoch 93/100\n",
      "1148/1148 [==============================] - 4s 3ms/step - loss: 1.4660 - accuracy: 0.3878 - val_loss: 5.9522 - val_accuracy: 0.0694\n",
      "Epoch 94/100\n",
      "1148/1148 [==============================] - 4s 4ms/step - loss: 1.4592 - accuracy: 0.3880 - val_loss: 5.9582 - val_accuracy: 0.0706\n",
      "Epoch 95/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 1.4515 - accuracy: 0.3897 - val_loss: 5.9611 - val_accuracy: 0.0680\n",
      "Epoch 96/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 1.4451 - accuracy: 0.3910 - val_loss: 5.9776 - val_accuracy: 0.0706\n",
      "Epoch 97/100\n",
      "1148/1148 [==============================] - 3s 3ms/step - loss: 1.4383 - accuracy: 0.3914 - val_loss: 5.9883 - val_accuracy: 0.0709\n",
      "Epoch 98/100\n",
      "1148/1148 [==============================] - 4s 4ms/step - loss: 1.4302 - accuracy: 0.3937 - val_loss: 5.9907 - val_accuracy: 0.0694\n",
      "Epoch 99/100\n",
      "1148/1148 [==============================] - 4s 4ms/step - loss: 1.4248 - accuracy: 0.3961 - val_loss: 6.0094 - val_accuracy: 0.0692\n",
      "Epoch 100/100\n",
      "1148/1148 [==============================] - 5s 4ms/step - loss: 1.4183 - accuracy: 0.3966 - val_loss: 6.0158 - val_accuracy: 0.0683\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Building model...')\n",
    "\n",
    "# create an LSTM network with a single LSTM\n",
    "input_ = Input(shape=(max_sequence_length,))\n",
    "initial_h = Input(shape=(LATENT_DIM,))\n",
    "initial_c = Input(shape=(LATENT_DIM,))\n",
    "\n",
    "x = embedding_layer(input_)\n",
    "lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "x, _, _ = lstm(x, initial_state=[initial_h, initial_c]) # don't need the states here\n",
    "dense = Dense(num_words, activation='softmax')\n",
    "output = dense(x)\n",
    "\n",
    "model = Model([input_, initial_h, initial_c], output)\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "  optimizer=Adam(lr=0.01),\n",
    "  # optimizer=SGD(lr=0.01, momentum=0.9),\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print('Training model...')\n",
    "z = np.zeros((len(input_sequences), LATENT_DIM))\n",
    "r = model.fit(\n",
    "  [input_sequences, z, z],\n",
    "  one_hot_targets,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "\n",
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# # accuracies\n",
    "# plt.plot(r.history['acc'], label='acc')\n",
    "# plt.plot(r.history['val_acc'], label='val_acc')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# make a sampling model\n",
    "input2 = Input(shape=(1,)) # we'll only input one word at a time\n",
    "x = embedding_layer(input2)\n",
    "x, h, c = lstm(x, initial_state=[initial_h, initial_c]) # now we need states to feed back in\n",
    "output2 = dense(x)\n",
    "sampling_model = Model([input2, initial_h, initial_c], [output2, h, c])\n",
    "\n",
    "\n",
    "# reverse word2idx dictionary to get back words\n",
    "# during prediction\n",
    "idx2word = {v:k for k, v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x1f94360cfc8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_line():\n",
    "    # initial inputs\n",
    "    np_input = np.array([[ word2idx['<sos>'] ]])\n",
    "    h = np.zeros((1, LATENT_DIM))\n",
    "    c = np.zeros((1, LATENT_DIM))\n",
    "\n",
    "    # so we know when to quit\n",
    "    eos = word2idx['<eos>']\n",
    "\n",
    "    # store the output here\n",
    "    output_sentence = []\n",
    "\n",
    "    for _ in range(max_sequence_length):\n",
    "        o, h, c = sampling_model.predict([np_input, h, c])\n",
    "\n",
    "        # print(\"o.shape:\", o.shape, o[0,0,:10])\n",
    "        # idx = np.argmax(o[0,0])\n",
    "        probs = o[0,0]\n",
    "        if np.argmax(probs) == 0:\n",
    "            print(\"wtf\")\n",
    "        probs[0] = 0\n",
    "        probs /= probs.sum()\n",
    "        idx = np.random.choice(len(probs), p=probs)\n",
    "        if idx == eos:\n",
    "            break\n",
    "\n",
    "        # accuulate output\n",
    "        output_sentence.append(idx2word.get(idx, '<WTF %s>' % idx))\n",
    "\n",
    "        # make the next input into model\n",
    "        np_input[0,0] = idx\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up so as he he guessed of you have held the confusion\n",
      "the headless aftermath,\n",
      "now slowly closing like a mouth-\n",
      "well, i were all married to go before\n",
      "---generate another? [Y/n]---y\n",
      "lifted the cellar going to sort of his eyes fire\n",
      "till you're a piercing little boy,\n",
      "someone came with cart and weary and you?'\n",
      "as pale and dim as if some say a trapper looking in\n",
      "---generate another? [Y/n]---y\n",
      "it was going to hear to-day?'\n",
      "the early mormons besides. like gnawed a shake our knees,\n",
      "who i see?\n",
      "two concerned for me\n",
      "---generate another? [Y/n]---n\n"
     ]
    }
   ],
   "source": [
    "# generate a 4 line poem\n",
    "\n",
    "while True:\n",
    "    for _ in range(4):\n",
    "        print(sample_line())\n",
    "\n",
    "    ans = input(\"---generate another? [Y/n]---\")\n",
    "    if ans and ans[0].lower().startswith('n'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
